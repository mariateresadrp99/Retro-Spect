## Code for "Retro-Spect: Evaluating Historical Representations in Diffusion Models"

![Evaluation Methodology](./evalutation_methodology.png)

Text-To-Image (TTI) models have become powerful tools for artistic creation and design. However, while existing research predominantly examines their embedded demographic and cultural biases, their ability to accurately represent historical contexts remains largely unexplored. In this work, we introduce a systematic and reproducible methodology for evaluating how TTI systems depict different historical periods across multiple dimensions. Our approach is grounded in HistVis, a curated dataset of 30,000 synthetic images generated by three state-of-the-art diffusion models using carefully designed prompts that depict universal human activities across diverse historical contexts. We evaluate historical depiction along three key dimensions: (1) Implicit Stylistic Associations: examining how models default to certain visual styles for specific periods; 
(2) Historical Consistency: detecting anachronisms such as the depiction of modern objects in historical scenes; and (3) Demographic Representation: comparing generated racial and gender distributions against historically plausible baselines derived from Large Language Models. We find that TTI models frequently stereotype past eras by adding visual stylistic properties not defined in the prompt, while also introducing anachronisms at notable rates and failing to reflect historically plausible demographic patterns. By providing a structured evaluation methodology and empirical insights, this work highlights critical gaps in the historical reasoning of TTI models. We release both the HistVis dataset and the accompanying tools needed to replicate our analysis and support the evaluation of additional TTI systems, laying the foundation for more historically responsible generative models.


## The HistVis Dataset

**HistVis** is a curated dataset of **30,000 synthetic images** generated by state-of-the-art text-to-image (TTI) diffusion models, designed to evaluate how these models represent historical contexts across time. The dataset supports the evaluation methodology introduced in *Retro-Spect: Evaluating Historical Representation in Diffusion Models*.


### Dataset Overview

The **HistVis** dataset contains 30,000 synthetic images generated from prompts describing historically situated human activities. Each prompt follows the format *"A person [activity] in the [time period]"*, combining 100 activities \(\mathcal{A} = \{a_1, \dots, a_{100}\}\) from 20 domains (e.g., art, work, communication) with 10 historical time periods \(\mathcal{T} = \{t_1, \dots, t_{10}\}\), spanning five centuries (17th–21st) and five 20th-century decades (1910s–1990s). For each pair \(\langle a, t \rangle\), 10 images were generated using three diffusion models—SDXL, SD3, and FLUX.1—resulting in a total of 30,000 images. Each image is annotated with the original prompt, activity category, time period, and model identifier.





### Dataset Access

## Evaluation Methods

### 1. Visual Style Prediction

This module predicts visual styles in images generated by TTI models. We use a VGG16-based classifier fine-tuned on six style categories: drawings, engravings, illustrations, paintings, photography (color or b&w). The script also computes a colorfulness score to help distinguish between black-and-white and color photography.

## Files

- `predict_visual_style.py`: Main script for running style prediction
- `utils.py`: Helper functions
- `model_weights/best_vgg16_only_last.keras`: Pretrained model weights

## Usage

```bash
python predict_visual_style.py \
  --image_dir path/to/images \
  --output_file style_predictions.csv
